import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import numpy as np

# Load the dataset
file_path = 'dataset1.csv' 
data = pd.read_csv(file_path)

# Select features for clustering
features = data[['App Sessions', 'Distance Travelled (km)', 'Calories Burned']]

# Normalize the data
scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)

# Determine the optimal number of clusters using the elbow method
wcss = [] #Within-Cluster Sum of Squares (WCSS)
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, random_state=42)
    kmeans.fit(scaled_features)
    wcss.append(kmeans.inertia_)

# Plot the elbow method
plt.figure(figsize=(10, 6))
plt.plot(range(1, 11), wcss, marker='o', linestyle='--')
plt.title('Elbow Method for Optimal Number of Clusters')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.grid(True)
plt.show()

# Apply K-means with the optimal number of clusters
optimal_clusters = 3  # Example: Assuming 3 is optimal based on the elbow plot
kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)
clusters = kmeans.fit_predict(scaled_features)

# Add cluster labels to the original data
data['Cluster'] = clusters

# Filter numeric columns
numeric_columns = data.select_dtypes(include=[np.number]).columns

# Analyze the clusters
cluster_analysis = data.groupby('Cluster')[numeric_columns].mean()
print(cluster_analysis)

